#----------------- Options ---------------
#----------------# Experiments -------------
seed=0
MODEL_NUM=1_${seed}
dataroot="../data/mnist_USPS"
dataset_mode="class_unaligned"
c_A_name="lenet_mnist_acc_97.5000.pt" # acc 91 in U
lambda_A=1
lambda_B=1
lambda_sem_A=1
lambda_sem_B=1
preprocess="resize_and_crop"
load_size=32
crop_size=32
pool_size=50
gpu_ids="-1" #for cpu
batch_size=10
direction="AtoB"
#direction="BtoA"
num_threads=4
#----------------- Epoch ----------------
niter=3
niter_decay=3
pretrain=0
pretrain_epoch=3
continue_train=0
epoch="latest"
epoch_count=1
#----------------- Basics ----------------
model="cycada"
DATE=`date "+%Y%m%d-%H%M%S"`
echo ${DATE}
name=${model}_${MODEL_NUM}
save_by_iter=0
checkpoints_dir="./checkpoints"
load_iter=0
max_dataset_size=50
phase="train"
serial_batches=0
monitor_gnorm=0
max_gnorm=500
no_flip=1
suffix=""
verbose=0
print_freq=1
eval_step_freq=$((${batch_size}*100))
save_epoch_freq=1 # for save
save_latest_freq=$((${batch_size}*1000))
#--------------- Optimizer---------------
lr=0.0002
c_lr=0.001
beta1=0.5
lr_policy="linear" #decay after niters elapsed
lr_decay_iters=50
#----------------- Network----------------
input_nc=3
output_nc=3
n_layers_D=4
ngf=4
ndf=4
netC="lenet"
netD="n_layers"
netG="resnet_2blocks"
no_dropout=1
norm="instance"
gan_mode="lsgan"
init_gain=0.02
init_type="normal"
#----------------- End -------------------

python train.py \
--monitor_gnorm=${monitor_gnorm} \
--batch_size=${batch_size} \
--beta1=${beta1} \
--checkpoints_dir=${checkpoints_dir} \
--continue_train=${continue_train} \
--crop_size=${crop_size} \
--c_A_name=${c_A_name} \
--c_lr=${c_lr} \
--dataroot=${dataroot} \
--dataset_mode=${dataset_mode} \
--direction=${direction} \
--seed=${seed} \
--epoch=${epoch} \
--epoch_count=${epoch_count} \
--gan_mode=${gan_mode} \
--gpu_ids=${gpu_ids} \
--init_gain=${init_gain} \
--init_type=${init_type} \
--input_nc=${input_nc} \
--lambda_A=${lambda_A} \
--lambda_B=${lambda_B} \
--lambda_sem_A=${lambda_sem_A} \
--lambda_sem_B=${lambda_sem_B} \
--load_iter=${load_iter} \
--load_size=${load_size} \
--lr=${lr} \
--lr_decay_iters=${lr_decay_iters} \
--lr_policy=${lr_policy} \
--max_dataset_size=${max_dataset_size} \
--model=${model} \
--n_layers_D=${n_layers_D} \
--name=${name} \
--ndf=${ndf} \
--netC=${netC} \
--netD=${netD} \
--netG=${netG} \
--ngf=${ngf} \
--niter=${niter} \
--niter_decay=${niter_decay} \
--no_dropout=${no_dropout} \
--no_flip=${no_flip} \
--norm=${norm} \
--num_threads=${num_threads} \
--output_nc=${output_nc} \
--phase=${phase} \
--pool_size=${pool_size} \
--print_freq=${print_freq} \
--preprocess=${preprocess} \
--pretrain=${pretrain} \
--pretrain_epoch=${pretrain_epoch} \
--save_by_iter=${save_by_iter} \
--save_epoch_freq=${save_epoch_freq} \
--eval_step_freq=${eval_step_freq} \
--save_latest_freq=${save_latest_freq} \
--serial_batches=${serial_batches} \
--suffix=${suffix} \
--verbose=${verbose} \
--max_gnorm=${max_gnorm} \
